{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cbe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as scio\n",
    "from scipy.io import savemat  \n",
    "import scipy.io as sio\n",
    "from sklearn.metrics import r2_score\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series,DataFrame\n",
    "from mealpy import FloatVar,SSA,WOA,AVOA,SRSR,SLO,FOX,SeaHO,PSO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc99ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "df = pd.read_excel('data.xlsx')\n",
    "df = df.iloc[:, 1:] \n",
    "X = df.drop(['Fu'], axis=1).values\n",
    "y = df['Fu'].values\n",
    "\n",
    "# Divide the training set and the testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "data_train_x=X_train\n",
    "data_train_y=y_train\n",
    "data_test_x=X_test\n",
    "data_test_y=y_test\n",
    "\n",
    "# Standardization\n",
    "X_mean, y_mean = data_train_x.mean(0), data_train_y.mean(0)\n",
    "X_std, y_std = data_train_x.std(0), data_train_y.std(0)\n",
    "\n",
    "data_train_x_nor = (data_train_x - X_mean) / X_std  \n",
    "data_test_x_nor = (data_test_x - X_mean) / X_std\n",
    "\n",
    "data_train_y_nor = (data_train_y - y_mean) / y_std  \n",
    "data_test_y_nor = (data_test_y - y_mean) / y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b3813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "\n",
    "def evaluate_regress(y_pre, y_true):\n",
    "   \n",
    "    MAE=np.sum(np.abs(y_pre-y_true))/len(y_true)\n",
    "    print('MAE为: ',str(MAE))\n",
    "\n",
    "    MAPE=np.sum(np.abs((y_pre-y_true)/y_true))/len(y_true)\n",
    "    print('MAPE为: ',str(MAPE))\n",
    "\n",
    "    MSE=np.sum((y_pre-y_true) ** 2)/len(y_true)\n",
    "    print('MSE为: ',str(MSE))\n",
    "    \n",
    "    RMSE=np.sqrt(MSE)\n",
    "    print('RMSE为: ',str(RMSE))\n",
    "\n",
    "    R2=r2_score(y_true, y_pre)\n",
    "    print('R2为: ',str(R2))\n",
    "\n",
    "    return MAE,MAPE,MSE,RMSE,R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Record the start time of the whole process.\n",
    "overall_start_time = time.time()\n",
    "\n",
    "# Create a global normalization object\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "best_fitness_history = []\n",
    "best_params_history = []\n",
    "\n",
    "def evaluate_model(solution):\n",
    "    hidden_layer_sizes = (int(solution[0]), int(solution[1]))  \n",
    "    learning_rate = solution[2]\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mae_scores = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(data_train_x):\n",
    "        X_train_fold, X_val_fold = data_train_x[train_index], data_train_x[val_index]\n",
    "        y_train_fold, y_val_fold = data_train_y[train_index], data_train_y[val_index]\n",
    "\n",
    "\n",
    "        X_train_fold = scaler_x.fit_transform(X_train_fold).astype(np.float32)\n",
    "        X_val_fold = scaler_x.transform(X_val_fold).astype(np.float32)\n",
    "\n",
    "        y_train_fold = scaler_y.fit_transform(y_train_fold.reshape(-1, 1)).flatten()\n",
    "        y_val_fold = scaler_y.transform(y_val_fold.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, activation='relu', \n",
    "                              solver='adam', learning_rate_init=learning_rate, \n",
    "                               max_iter=2000, \n",
    "                             random_state=42, verbose=0)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "\n",
    "        mae_fold = mean_absolute_error(y_val_fold, y_pred)\n",
    "        mae_scores.append(mae_fold)\n",
    "    \n",
    "    if mae_scores:\n",
    "        mean_mae = np.mean(mae_scores)\n",
    "        \n",
    "        if len(best_fitness_history) < 150 or mean_mae < best_fitness_history[-1]:\n",
    "            best_fitness_history.append(mean_mae)\n",
    "            best_params_history.append(solution)\n",
    "\n",
    "        if len(best_fitness_history) > 150:\n",
    "            best_fitness_history.pop(0)\n",
    "            best_params_history.pop(0)\n",
    "\n",
    "        return mean_mae\n",
    "    else:\n",
    "        return float('inf')\n",
    "\n",
    "# Define parameter ranges\n",
    "param_grid = {\n",
    "    \"obj_func\": evaluate_model,\n",
    "    \"bounds\": [\n",
    "        FloatVar(lb=8, ub=128),   \n",
    "        FloatVar(lb=8, ub=128),   \n",
    "        FloatVar(lb=0.01, ub=0.1), \n",
    "    ],\n",
    "    \"minmax\": \"min\"\n",
    "}\n",
    "\n",
    "# Set parameters for the AVOA algorithm\n",
    "epoch = 150\n",
    "pop_size = 15\n",
    "AVOA_model = AVOA.OriginalAVOA(epoch=epoch, pop_size=pop_size)\n",
    "\n",
    "# Solve the optimization problem\n",
    "AVOA_best = AVOA_model.solve(param_grid)\n",
    "\n",
    "# Create a DataFrame to save the best fitness and hyperparameters\n",
    "best_history_df = pd.DataFrame({\n",
    "    'Best_Fitness': best_fitness_history,\n",
    "    'Hidden_Layer_1': [int(param[0]) for param in best_params_history], \n",
    "    'Hidden_Layer_2': [int(param[1]) for param in best_params_history], \n",
    "    'Learning_Rate': [param[2] for param in best_params_history]\n",
    "})\n",
    "\n",
    "# Best parameters\n",
    "final_best_params = AVOA_best.solution\n",
    "best_hidden_layers = (int(final_best_params[0]), int(final_best_params[1]))\n",
    "best_learning_rate = final_best_params[2]\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "output_path = 'optimized_paras_AVOA_MLP.xlsx'\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    best_history_df.to_excel(writer, sheet_name='Best_Parameters', index=False)\n",
    "    pd.DataFrame([final_best_params], columns=[f'Final_Param_{i+1}' for i in range(len(final_best_params))]).to_excel(writer, sheet_name='Final_Best_Parameters', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use the best parameters to train the final model\n",
    "best_model = MLPRegressor(hidden_layer_sizes=best_hidden_layers, activation='relu', \n",
    "                           solver='adam', learning_rate_init=best_learning_rate, \n",
    "                           max_iter=2000, \n",
    "                           random_state=42)\n",
    "best_model.fit(data_train_x_nor, data_train_y_nor)\n",
    "\n",
    "# Prediction\n",
    "y_pred_test_nor = best_model.predict(data_test_x_nor)\n",
    "y_pred_train_nor = best_model.predict(data_train_x_nor)\n",
    "\n",
    "# Anti-standardization\n",
    "y_pred_test = y_pred_test_nor * y_std + y_mean\n",
    "y_pred_test1 = y_pred_test.reshape(len(y_pred_test), 1)\n",
    "data_test_y1 = data_test_y.reshape(len(data_test_y), 1) \n",
    "\n",
    "y_pred_train = y_pred_train_nor * y_std + y_mean\n",
    "y_pred_train1 = y_pred_train.reshape(len(y_pred_train), 1)\n",
    "data_train_y1 = data_train_y.reshape(len(data_train_y), 1)\n",
    "\n",
    "# Calculation error\n",
    "T_MAE, T_MAPE, T_MSE, T_RMSE, T_R2 = evaluate_regress(y_pred_test1, data_test_y1)\n",
    "R_MAE, R_MAPE, R_MSE, R_RMSE, R_R2 = evaluate_regress(y_pred_train1, data_train_y1)\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "errors_test = pd.DataFrame({\n",
    "    'test—Metric': ['MAE', 'MAPE', 'MSE', 'RMSE', 'R2'],\n",
    "    'test—Value': [T_MAE, T_MAPE, T_MSE, T_RMSE, T_R2]\n",
    "})\n",
    "errors_train = pd.DataFrame({\n",
    "    'train—Metric': ['MAE', 'MAPE', 'MSE', 'RMSE', 'R2'],\n",
    "    'train—Value': [R_MAE, R_MAPE, R_MSE, R_RMSE, R_R2]\n",
    "})\n",
    "\n",
    "# Reconstruct predictions and true values\n",
    "predictions = np.concatenate((y_pred_train[:, np.newaxis], y_pred_test[:, np.newaxis]), axis=0)\n",
    "\n",
    "# Fix: directly reshape data_train_y and data_test_y as numpy arrays\n",
    "truevalues = np.concatenate((data_train_y[:, np.newaxis], data_test_y[:, np.newaxis]), axis=0)\n",
    "\n",
    "# Flatten the arrays\n",
    "predictions = predictions.ravel()\n",
    "truevalues = truevalues.ravel()\n",
    "\n",
    "results_df = pd.DataFrame({'Predictions': predictions, 'True Values': truevalues})\n",
    "\n",
    "\n",
    "# Save the results to Excel\n",
    "output_path_results = 'results_optimized_AVOA_MLP.xlsx'\n",
    "with pd.ExcelWriter(output_path_results) as writer:\n",
    "    errors_test.to_excel(writer, sheet_name='Test_Errors', index=False)\n",
    "    errors_train.to_excel(writer, sheet_name='Train_Errors', index=False)\n",
    "    results_df.to_excel(writer, sheet_name='Predictions', index=False)\n",
    "\n",
    "# Record the end time of the whole process.\n",
    "overall_end_time = time.time()\n",
    "overall_total_time = overall_end_time - overall_start_time\n",
    "print(f\"Total time taken: {overall_end_time - overall_start_time:.2f} seconds\")\n",
    "\n",
    "# Save total runtime to an Excel file\n",
    "with pd.ExcelWriter(output_path_results, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    process_time_df = pd.DataFrame({\n",
    "        'Total_Process_Time_Seconds': [overall_total_time]\n",
    "    })\n",
    "    process_time_df.to_excel(writer, sheet_name='Process_Time', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a047d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
